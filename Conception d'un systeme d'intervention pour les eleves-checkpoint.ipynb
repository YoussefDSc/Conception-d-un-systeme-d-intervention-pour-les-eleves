{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Le but de ce projet est d'identifier les élèves qui pourraient avoir besoin d'une intervention précoce avant l'obtention de leur diplôme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données\n",
    "La cellule de code ci-dessous est pour charger les bibliothèques Python nécessaires et charger les données élèves. La dernière colonne de cet ensemble de données, \" passed \", sera notre étiquette cible (que l'étudiant ait obtenu ou non son diplôme). Toutes les autres colonnes sont des caractéristiques de chaque élève."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
       "0  ...         no       no       4         3      4    1    1      3        6   \n",
       "1  ...        yes       no       5         3      3    1    1      3        4   \n",
       "2  ...        yes       no       4         3      2    2    3      3       10   \n",
       "3  ...        yes      yes       3         2      2    1    1      5        2   \n",
       "4  ...         no       no       4         3      2    1    2      5        4   \n",
       "\n",
       "  passed  \n",
       "0     no  \n",
       "1     no  \n",
       "2    yes  \n",
       "3    yes  \n",
       "4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "student_data = pd.read_csv(r\"C:\\Users\\acer\\Desktop\\student-data.csv\")\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C'est un DataFrame 395 x 31\n",
    "student_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le type de données est un pandas DataFrame\n",
    "# Hence I can use pandas DataFrame methods\n",
    "type(student_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en œuvre : Exploration des données\n",
    "Commençons par examiner l'ensemble de données pour déterminer le nombre d'étudiants sur lesquels nous avons de l'information et pour connaître le taux d'obtention de diplôme chez ces étudiants. Dans la cellule de code ci-dessous, nous calculerons ce qui suit :\n",
    "\n",
    "- Le nombre total d'étudiants, n_étudiants.\n",
    "- Le nombre total de fonctionnalités pour chaque étudiant, n_fonctionnalités.\n",
    "- Le nombre d'étudiants qui ont réussi, n_passed.\n",
    "- Le nombre de ces étudiants qui ont échoué, n_failed.\n",
    "- Le taux de diplomation de la classe, grad_rate, en pourcentage (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre d'étudiants : 395\n",
      "nombre de caractéristiques : 30\n",
      "nombre d'étudiants réussis  : 265\n",
      "nombre d'étudiants ayant échoué : 130\n",
      "Le taux d'obtention du diplôme est de : 67.09%\n"
     ]
    }
   ],
   "source": [
    "## nombre d'étudiants\n",
    "nb_student=student_data.shape[0]\n",
    "## nombre de fonctionnalités\n",
    "nb_feat=student_data.shape[1]-1\n",
    "## nombre d'étudiants qui ont réussi\n",
    "student_passed=student_data.loc[student_data.passed==\"yes\",\"passed\"]\n",
    "\n",
    "nb_passed=student_passed.shape[0]\n",
    "## nombre d'étudiants qui ont échoué\n",
    "student_failed=student_data.loc[student_data.passed==\"no\",\"passed\"]\n",
    "nb_failed=student_failed.shape[0]\n",
    "## taux d'obtention de diplôme\n",
    "grad_rate=nb_passed*100/(nb_passed+nb_failed)\n",
    "\n",
    "print (\"nombre d'étudiants : {}\".format(nb_student))\n",
    "print(\"nombre de caractéristiques : {}\".format(nb_feat))\n",
    "print(\"nombre d'étudiants réussis  : {}\".format(nb_passed))\n",
    "print(\"nombre d'étudiants ayant échoué : {}\".format(nb_failed))\n",
    "print(\"Le taux d'obtention du diplôme est de : {:.2f}%\".format(grad_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "Dans cette section, nous préparerons les données pour la modélisation, la formation et les essais.\n",
    "\n",
    "Nous allons identifier les colonnes de caractéristiques et de cibles\n",
    "Il arrive souvent que les données que nous obtenons contiennent des caractéristiques non numériques. Cela peut être un problème, car la plupart des algorithmes d'apprentissage machine s'attendent à ce que les données numériques effectuent des calculs avec.\n",
    "\n",
    "La cellule de code ci-dessous  sépare les données élèves en colonnes de caractéristiques et de cibles afin de voir si certaines caractéristiques sont non numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
       "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
       "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
       "       'Walc', 'health', 'absences', 'passed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colonnes\n",
    "student_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'passed'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Nous voulons obtenir le nom de la colonne \"passed\" qui est le dernier nom de la colonne \n",
    "student_data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
       "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
       "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
       "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
       "       'Walc', 'health', 'absences'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ceci obtiendrait tout sauf le dernier élément qui est \"passed\".\n",
    "student_data.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes en vedette : \n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      " Colonne cible : passed\n",
      "Informations en vedette : \n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraire des colonnes de caractéristiques\n",
    "# Comme nous l'avons vu plus haut, nous obtenons toutes les colonnes à l'exception de \"passed\" ici, mais nous le convertissons en une liste\n",
    "featured_col=list(student_data.columns[:-1])\n",
    "target_col=student_data.columns[-1]\n",
    "# Afficher la liste des colonnes\n",
    "print(\"Colonnes en vedette : \\n{}\".format(featured_col))\n",
    "print(\"\\n Colonne cible : {}\".format(target_col))\n",
    "# Séparer les données en données de caractéristiques et données cibles (X_all et y_all, respectivement)\n",
    "X_all=student_data[featured_col]\n",
    "y_all=student_data[target_col]\n",
    "# Afficher les informations sur les caractéristiques en print les cinq premières lignes\n",
    "print(\"Informations en vedette : \\n{}\".format(X_all.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colonnes des caractéristiques de prétraitement\n",
    "Il y a plusieurs colonnes non numériques qui doivent être converties ! Beaucoup d'entre eux sont simplement oui/non, par exemple Internet. Ceux-ci peuvent être raisonnablement convertis en valeurs de 1/0 (binaires).\n",
    "\n",
    "D'autres colonnes, comme Mjob et Fjob, ont plus de deux valeurs et sont appelées variables catégorielles. La façon recommandée pour gérer une telle colonne est de créer autant de colonnes que possible (par exemple Fjob_teacher, Fjob_other, Fjob_services, etc.), et d'attribuer un 1 à l'une d'elles et 0 à toutes les autres.\n",
    "\n",
    "Ces colonnes générées sont parfois appelées variables factices, et nous utiliserons la fonction pandas.get_dummies() pour effectuer cette transformation. La cellule de code ci-dessous  exécute la routine de prétraitement décrite dans cette section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes de caractéristiques traitées (48 caractéristiques totales):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Prétraite les données élèves et convertit les variables binaires non numériques en\n",
    "        variables binaires (0/1). Convertit les variables catégorielles en variables factices. '''\n",
    "\n",
    "    # Initialiser le nouveau DataFrame de sortie\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Étudier chaque colonne de caractéristiques pour les données\n",
    "    for col, col_data in X.iteritems():\n",
    "\n",
    "        # Si le type de données n'est pas numérique, remplacer toutes les valeurs oui/non par 1/0.\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Si le type de données est catégorique, convertir en variables fictives\n",
    "        if col_data.dtype == object:\n",
    "             col_data = pd.get_dummies(col_data, prefix = col)\n",
    "\n",
    "        # Collecter les colonnes révisées\n",
    "        output = output.join(col_data)\n",
    "\n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print (\"Colonnes de caractéristiques traitées ({} caractéristiques totales):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en œuvre : Répartition des données de formation et de test\n",
    "Jusqu'à présent, nous avons converti toutes les caractéristiques catégorielles en valeurs numériques. Pour l'étape suivante, nous divisons les données (à la fois les caractéristiques et les étiquettes correspondantes) en ensembles de formation et de test. Dans la cellule de code suivante ci-dessous, il est implémenté ce qui suit :\n",
    "\n",
    "- Mélanger aléatoirement et diviser les données (X_all, y_all) en sous-ensembles de formation et de test.\n",
    "- Utiliser 300 points de formation (environ 75 %) et 95 points de test (environ 25 %).\n",
    "- Définir un random_state pour la ou les fonctions utilisées, le cas échéant.\n",
    "- Stocker les résultats dans X_train, X_test, y_train et y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Importez toutes les fonctionnalités supplémentaires dont vous pourriez avoir besoin ici\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'ensemble d'entraînement a 300 échantillons.\n",
      "L'ensemble de test a  95 échantillons.\n"
     ]
    }
   ],
   "source": [
    "# Pour le fractionnement initial train/test, nous pouvons obtenir une stratification en utilisant simplement stratify = y_all :\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, stratify = y_all, test_size=95, random_state=42)\n",
    "\n",
    "# Afficher les résultats du fractionnement\n",
    "print (\"L'ensemble d'entraînement a {} échantillons.\".format(X_train.shape[0]))\n",
    "print (\"L'ensemble de test a  {} échantillons.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de formation et d'évaluation\n",
    "Dans cette section, on choisira 3 modèles d'apprentissage supervisé qui sont appropriés pour ce problème et disponibles en scikit-learn. On adaptera ensuite le modèle à différentes tailles de données d'entraînement (100 points de données, 200 points de données et 300 points de données) et mesurera le score F1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "La cellule de code ci-dessous  permet d'initialiser trois fonctions d'aide utilisé pour former et tester les trois modèles d'apprentissage supervisé que vous avez choisis ci-dessus. Les fonctions sont les suivantes :\n",
    "\n",
    "train_classifier - prend comme entrée un classificateur et des données d'entraînement et adapte le classificateur aux données.\n",
    "predict_labels - prend en entrée un classificateur d'ajustement, des caractéristiques et un étiquetage de cible et fait des prédictions en utilisant le score F1.\n",
    "train_predict - prend en entrée un classificateur, et les données de formation et de test, et exécute train_clasifier et predict_labels.\n",
    "Cette fonction rapportera le score F1 séparément pour les données d'entraînement et d'examen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Adapte un classificateur aux données d'entraînement. '''\n",
    "\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "\n",
    "    print (\"Modèle formé en {:.4f} seconds\".format(end - start))\n",
    "\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Fait des prédictions à l'aide d'un classificateur d'ajustement basé sur le score F1. '''\n",
    "\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "\n",
    "    print (\"A fait des prédictions dans {:.4f} seconds.\".format(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' S'entraîner et prédire à l'aide d'un classificateur basé sur le score F1. '''\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"L'Entrainement a {} utilisant une taille de l'ensemble de formation de {}. . .\".format(clf.__class__.__name__, len(X_train)))\n",
    "\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "\n",
    "    print (\"Score F1 pour le set d'entraînement: {:.4f}.\".format(predict_labels(clf, X_train, y_train)))\n",
    "    print(\"Score F1 pour le set de test: {:.4f}.\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation : Paramètres de performance du modèle\n",
    "Avec les fonctions prédéfinies ci-dessus, on va maintenant importer les trois modèles d'apprentissage supervisé et exécuter la fonction train_predict pour chacun.  Dans la cellule de code suivante, on va implémenter ce qui suit :\n",
    "\n",
    "- Importer les trois modèles d'apprentissage supervisé.\n",
    "- Initialiser les trois modèles et les stocker dans clf_A, clf_B et clf_C.\n",
    "- Utiliser un random_state pour chaque modèle utilisé; le cas échéant.\n",
    "*Remarque* : On utilisera les paramètres par défaut pour chaque modèle - \n",
    "- Créer les différentes tailles d'ensembles d'entraînement à utiliser pour entraîner chaque modèle.\n",
    "- Adapter chaque modèle à la taille de chaque ensemble d'entraînement et faire des prédictions sur l'ensemble d'essai (9 au total).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GaussianNB: \n",
      "\n",
      "\n",
      "L'Entrainement a GaussianNB utilisant une taille de l'ensemble de formation de 100. . .\n",
      "Modèle formé en 0.0040 seconds\n",
      "A fait des prédictions dans 0.0030 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.7752.\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set de test: 0.6457.\n",
      "\n",
      "L'Entrainement a GaussianNB utilisant une taille de l'ensemble de formation de 200. . .\n",
      "Modèle formé en 0.0030 seconds\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8060.\n",
      "A fait des prédictions dans 0.0050 seconds.\n",
      "Score F1 pour le set de test: 0.7218.\n",
      "\n",
      "L'Entrainement a GaussianNB utilisant une taille de l'ensemble de formation de 300. . .\n",
      "Modèle formé en 0.0040 seconds\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8134.\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set de test: 0.7761.\n",
      "\n",
      "LogisticRegression: \n",
      "\n",
      "\n",
      "L'Entrainement a LogisticRegression utilisant une taille de l'ensemble de formation de 100. . .\n",
      "Modèle formé en 0.0020 seconds\n",
      "A fait des prédictions dans 0.0010 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8671.\n",
      "A fait des prédictions dans 0.0030 seconds.\n",
      "Score F1 pour le set de test: 0.7068.\n",
      "\n",
      "L'Entrainement a LogisticRegression utilisant une taille de l'ensemble de formation de 200. . .\n",
      "Modèle formé en 0.0060 seconds\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8211.\n",
      "A fait des prédictions dans 0.0010 seconds.\n",
      "Score F1 pour le set de test: 0.7391.\n",
      "\n",
      "L'Entrainement a LogisticRegression utilisant une taille de l'ensemble de formation de 300. . .\n",
      "Modèle formé en 0.0040 seconds\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8512.\n",
      "A fait des prédictions dans 0.0010 seconds.\n",
      "Score F1 pour le set de test: 0.7500.\n",
      "\n",
      "SVC: \n",
      "\n",
      "\n",
      "L'Entrainement a SVC utilisant une taille de l'ensemble de formation de 100. . .\n",
      "Modèle formé en 0.0030 seconds\n",
      "A fait des prédictions dans 0.0010 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8354.\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set de test: 0.8025.\n",
      "\n",
      "L'Entrainement a SVC utilisant une taille de l'ensemble de formation de 200. . .\n",
      "Modèle formé en 0.0060 seconds\n",
      "A fait des prédictions dans 0.0040 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8431.\n",
      "A fait des prédictions dans 0.0020 seconds.\n",
      "Score F1 pour le set de test: 0.8105.\n",
      "\n",
      "L'Entrainement a SVC utilisant une taille de l'ensemble de formation de 300. . .\n",
      "Modèle formé en 0.0100 seconds\n",
      "A fait des prédictions dans 0.0060 seconds.\n",
      "Score F1 pour le set d'entraînement: 0.8664.\n",
      "A fait des prédictions dans 0.0030 seconds.\n",
      "Score F1 pour le set de test: 0.8052.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO : Importer les trois modèles d'apprentissage supervisé de sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# TODO : Initialiser les trois modèles\n",
    "clf_A = GaussianNB()\n",
    "clf_B = LogisticRegression(random_state=42)\n",
    "clf_C = SVC(random_state=42)\n",
    "\n",
    "# TODO : Configurez les tailles des sets d'entraînement\n",
    "X_train_100 = X_train.iloc[:100, :]\n",
    "y_train_100 = y_train.iloc[:100]\n",
    "\n",
    "X_train_200 = X_train.iloc[:200, :]\n",
    "y_train_200 = y_train.iloc[:200]\n",
    "\n",
    "X_train_300 = X_train.iloc[:300, :]\n",
    "y_train_300 = y_train.iloc[:300]\n",
    "\n",
    "# TODO : Exécuter la fonction'train_predict' pour chaque classificateur et chaque taille de jeu d'apprentissage\n",
    "# train_predict(clf, X_train, y_train, y_train, X_test, y_test)\n",
    "\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    print(\"\\n{}: \\n\".format(clf.__class__.__name__))\n",
    "    for n in [100, 200, 300]:\n",
    "        train_predict(clf, X_train[:n], y_train[:n], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "La performance prédictive des MVC est légèrement supérieure à celle de Naive Bayes. Cependant, il est important de noter que le temps de calcul des MVC augmenterait beaucoup plus rapidement que celui de Naive Bayes avec plus de données, et que nos coûts augmenteraient de façon exponentielle lorsque nous aurions plus d'étudiants. D'un autre côté, le temps de calcul de Naive Bayes augmenterait linéairement avec plus de données, et notre coût n'augmenterait pas aussi rapidement. Par conséquent, Naive Bayes offre une bonne alternative aux MVC en tenant compte de sa performance sur un petit ensemble de données et sur un ensemble de données potentiellement important et croissant.\n",
    "\n",
    "Par conséquent, nous comparons Naive Bayes et Logistic Regression. Bien que les résultats montrent que la régression logistique est légèrement inférieure à celle de Naive Bayes en termes de performance prédictive, un léger ajustement du modèle de régression logistique permettrait facilement d'obtenir une performance prédictive bien meilleure que celle de Naive Bayes. Cela contraste avec Naive Bayes où nous n'avons pas l'occasion d'accorder le modèle. Par conséquent, nous devrions opter pour la régression logistique.\n",
    "\n",
    "Notation Big O pour les 3 algorithmes:\n",
    "\n",
    "- Naive Bayes :\n",
    "O(n)\n",
    "\n",
    "\n",
    "- Régression logistique :\n",
    "O(C^n)\n",
    "\n",
    "\n",
    "- Support Vector Machines :\n",
    "O(n^3) avec noyau sigmoïde ou O(n^2) avec des complexités d'espace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
